{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models to Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from modeling.train import rounded_equal\n",
    "from modeling.simple_rnn import SIMPLE_RNN_PATH\n",
    "\n",
    "model = load_model(SIMPLE_RNN_PATH, custom_objects={\"rounded_equal\": rounded_equal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.predict([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.document_manager import DocumentManager\n",
    "from preprocessing.dataset_manager import DatasetManager\n",
    "from modeling.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "doc_manager = DocumentManager()\n",
    "doc_manager.cache_documents()\n",
    "dataset_manager = DatasetManager(tokenizer)\n",
    "\n",
    "dataset = dataset_manager.get_dataset_from_documents(doc_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis True Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.enums import EmotionTag\n",
    "\n",
    "over_zero_count = {}\n",
    "score_counts = {}\n",
    "\n",
    "for i, label in enumerate(dataset[\"train_labels\"]):\n",
    "    y_true = EmotionTag.map_labels_to_tags(label)\n",
    "    count_of_true = sum([ bool(score) for _, score in y_true ])\n",
    "    if (count_of_true in over_zero_count):\n",
    "        over_zero_count[count_of_true] +=1 \n",
    "    else:\n",
    "        over_zero_count[count_of_true] = 1\n",
    "        \n",
    "    for tag, score in y_true:\n",
    "        if (score in score_counts):\n",
    "            score_counts[score] += 1\n",
    "        else:\n",
    "            score_counts[score] = 1\n",
    "\n",
    "print(\"over zero count: \\n\", sorted(word_count_true.items(), key=lambda x: x[0]), \"\\n\")\n",
    "print(\"scores count: \\n\", sorted(score_counts.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def format_prediction(prediction):\n",
    "    y_pred = EmotionTag.map_labels_to_tags(prediction[0])\n",
    "    rounded_y_pred = [ (tag, (np.round(score * 1e4) / 1e4)) for tag, score in y_pred ]\n",
    "    return rounded_y_pred\n",
    "\n",
    "def \n",
    "\n",
    "for i in range(5):\n",
    "    text = dataset[\"valid_texts\"][i]\n",
    "    y_true = EmotionTag.map_labels_to_tags(dataset[\"valid_labels\"][i])\n",
    "    prediction = model.predict(np.array([dataset[\"valid_sequences\"][i]]))\n",
    "    y_pred = format_prediction(prediction)\n",
    "    \n",
    "    print(\"Text: \\n\", text)\n",
    "    print(\"y_true, predict: \\n\", y_true, \"\\n\")\n",
    "    print(y_pred)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(dataset[\"valid_sequences\"][i])\n",
    "\n",
    "predict = model.predict(np.array([dataset[\"valid_sequences\"][i]]))\n",
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
